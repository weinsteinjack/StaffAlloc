{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Capstone Phase 2: AI-Powered Architecture & Data Design\n",
        "\n",
        "**Project:** StaffAlloc ‚Äì AI-Powered Project Staffing & Hours Allocation Tool\n",
        "\n",
        "**Objective:** Apply the Phase 2 guidance from the capstone README to transform the PRD into actionable architectural artifacts. We will prompt an LLM to propose a system architecture, generate PlantUML diagrams, capture key architectural decisions, and produce a normalized relational schema that aligns with the StaffAlloc vision.\n",
        "\n",
        "---\n",
        "\n",
        "## üìñ Overview\n",
        "\n",
        "Phase 2 concentrates on acting as the system architect. Following the README playbook, this notebook guides an AI co-pilot to:\n",
        "\n",
        "1. Synthesize the architecture from the PRD.\n",
        "2. Generate diagrams-as-code (PlantUML) artifacts.\n",
        "3. Capture architecture decision records (ADRs).\n",
        "4. Produce the relational database schema that will feed later phases.\n",
        "\n",
        "> All prompts use the authoritative context from `Artifacts/Documentation/prd.md`. Before running the notebook, verify your API credentials and project structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Before You Begin\n",
        "\n",
        "Make sure the following prerequisites are satisfied:\n",
        "\n",
        "1. `.env` file exists in the project root with a valid `GOOGLE_API_KEY` (see `SETUP.md`).\n",
        "2. Dependencies from `requirements.txt` are installed in your active environment.\n",
        "3. The Phase 1 artifacts‚Äîespecially `Artifacts/Documentation/prd.md`‚Äîare present.\n",
        "4. You have network access to call the selected LLM provider.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Install Required Packages\n",
        "\n",
        "Run this cell first to ensure the current kernel has the libraries needed for architecture generation, diagram rendering, and file management.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing required packages in the current kernel environment...\n",
            "Python executable: c:\\Users\\640109\\T1Capstone\\.venv\\Scripts\\python.exe\n",
            "Python version: 3.13.9 (tags/v3.13.9:8183fa5, Oct 14 2025, 14:09:13) [MSC v.1944 64 bit (AMD64)]\n",
            "======================================================================\n",
            "\n",
            "üì¶ Installing python-dotenv...\n",
            "   ‚úì python-dotenv installed successfully\n",
            "\n",
            "üì¶ Installing google-genai...\n",
            "   ‚úì google-genai installed successfully\n",
            "\n",
            "üì¶ Installing plantuml...\n",
            "   ‚úì plantuml installed successfully\n",
            "\n",
            "üì¶ Installing graphviz...\n",
            "   ‚úì graphviz installed successfully\n",
            "\n",
            "üì¶ Installing pydantic...\n",
            "   ‚úì pydantic installed successfully\n",
            "\n",
            "======================================================================\n",
            "‚úÖ Package installation complete!\n",
            "\n",
            "Proceed to Step 1.\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "print(\"Installing required packages in the current kernel environment...\")\n",
        "print(f\"Python executable: {sys.executable}\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "required_packages = [\n",
        "    \"python-dotenv\",\n",
        "    \"google-genai\",\n",
        "    \"plantuml\",\n",
        "    \"graphviz\",\n",
        "    \"pydantic\",\n",
        "]\n",
        "\n",
        "for package in required_packages:\n",
        "    print(f\"\\nüì¶ Installing {package}...\")\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "        print(f\"   ‚úì {package} installed successfully\")\n",
        "    except subprocess.CalledProcessError as exc:\n",
        "        print(f\"   ‚ùå Failed to install {package}: {exc}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ Package installation complete!\")\n",
        "print(\"\\nProceed to Step 1.\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Environment Setup\n",
        "\n",
        "This step mirrors the pattern from Phase 1. We will:\n",
        "\n",
        "1. Locate the project root and add it to the Python path.\n",
        "2. Load environment variables from `.env`.\n",
        "3. Import reusable helper utilities.\n",
        "4. Initialize the LLM client (default: `gemini-2.5-pro`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Locating project root and preparing environment...\n",
            "Project root: c:\\Users\\640109\\T1Capstone\n",
            "‚úì python-dotenv available\n",
            "‚úì Loaded environment variables from c:\\Users\\640109\\T1Capstone\\.env\n",
            "‚úì GOOGLE_API_KEY detected (AIzaSyBZ..._C7Q)\n",
            "‚úì Imported utilities from utils.py\n",
            "\n",
            "Initializing LLM client...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-05 14:29:41,305 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LLM ready (provider=google, model=gemini-2.5-pro)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "print(\"üìÅ Locating project root and preparing environment...\")\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "print(f\"Project root: {project_root}\")\n",
        "\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    print(\"‚úì python-dotenv available\")\n",
        "except ImportError:\n",
        "    raise RuntimeError(\"python-dotenv is not installed. Run Step 0 first.\")\n",
        "\n",
        "env_path = os.path.join(project_root, \".env\")\n",
        "if os.path.exists(env_path):\n",
        "    load_dotenv(env_path)\n",
        "    print(f\"‚úì Loaded environment variables from {env_path}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è WARNING: .env file missing at {env_path}\")\n",
        "\n",
        "api_key_preview = os.getenv(\"GOOGLE_API_KEY\")\n",
        "if api_key_preview:\n",
        "    masked = f\"{api_key_preview[:8]}...{api_key_preview[-4:]}\" if len(api_key_preview) > 12 else \"***\"\n",
        "    print(f\"‚úì GOOGLE_API_KEY detected ({masked})\")\n",
        "else:\n",
        "    raise RuntimeError(\"GOOGLE_API_KEY not found. Add it to your .env file.\")\n",
        "\n",
        "try:\n",
        "    from utils import (\n",
        "        setup_llm_client,\n",
        "        get_completion,\n",
        "        clean_llm_output,\n",
        "        save_artifact,\n",
        "        load_artifact,\n",
        "    )\n",
        "    print(\"‚úì Imported utilities from utils.py\")\n",
        "except ImportError as err:\n",
        "    raise RuntimeError(f\"Unable to import project utilities: {err}\")\n",
        "\n",
        "print(\"\\nInitializing LLM client...\")\n",
        "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
        "print(f\"‚úÖ LLM ready (provider={api_provider}, model={model_name})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Phase 1 Artifacts\n",
        "\n",
        "Fetch the authoritative PRD so we can embed it in subsequent prompts. The helper utilities persist artifacts under `Artifacts/`, matching the structure used in earlier labs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Loaded PRD from Artifacts/Documentation/prd.md\n",
            "Preview (first 600 characters):\n",
            "\n",
            "# Product Requirements Document: StaffAlloc\n",
            "**Version:** 1.0\n",
            "**Date:** November 5, 2025\n",
            "**Author:** Senior Product Manager\n",
            "**Status:** Draft\n",
            "\n",
            "## 1. Executive Summary & Vision\n",
            "\n",
            "### Product Name\n",
            "StaffAlloc\n",
            "\n",
            "### Overview\n",
            "StaffAlloc is an intelligent, AI-powered staffing management application designed to replace cumbersome and error-prone spreadsheets. It provides project managers, directors, and resource managers with a centralized platform to create projects, allocate employee hours, track budgets, and optimize resource utilization across the entire organization.\n",
            "\n",
            "### Purpose\n",
            "The primary purpos\n"
          ]
        }
      ],
      "source": [
        "prd_path = \"Artifacts/Documentation/prd.md\"\n",
        "prd_content = load_artifact(prd_path)\n",
        "\n",
        "if prd_content:\n",
        "    print(f\"‚úì Loaded PRD from {prd_path}\")\n",
        "    print(\"Preview (first 600 characters):\\n\")\n",
        "    print(prd_content[:600])\n",
        "else:\n",
        "    raise FileNotFoundError(f\"PRD not found at {prd_path}. Confirm Phase 1 artifacts exist.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Architecture Challenges\n",
        "\n",
        "Following the README guidance, each challenge pairs a targeted prompt with automated artifact saving. For Phase 2 we align the architecture with the Day 3 FastAPI + SQLite labs so the full stack can run locally without paid cloud services.\n",
        "\n",
        "### Challenge 1 ‚Äì System Architecture Narrative\n",
        "\n",
        "**Goal:** Produce a comprehensive `architecture.md` document for a local-first prototype. Focus on:\n",
        "\n",
        "- High-level system overview sized for a single developer workstation\n",
        "- Responsibilities inside the FastAPI monolith, React client, and supporting utilities\n",
        "- Local integrations (SQLite, file-based storage, optional local vector database, SMTP dev server)\n",
        "- Data flow, privacy, and configuration management on a single machine\n",
        "- Evolution notes for scaling beyond the prototype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generating architecture narrative ---\n",
            "# StaffAlloc Local-First Prototype: Architecture Document\n",
            "\n",
            "**Author:** Senior Solutions Architect\n",
            "**Version:** 1.0\n",
            "**Date:** Current Date\n",
            "\n",
            "## 1. Executive Summary\n",
            "\n",
            "This document outlines the technical architecture for a local-first prototype of the StaffAlloc platform. The primary objective of this prototype is to validate the core user experience and AI-driven features on a single developer laptop, eliminating the need for paid cloud dependencies and enabling rapid, cost-effective iteration. By building a fully functional, self-contained application, we can test the most critical user stories‚Äîfrom the interactive allocation grid to the AI-powered RAG chat‚Äîand gather essential feedback before committing to a scalable cloud infrastructure.\n",
            "\n",
            "Our technology stack is aligned with modern, effic\n",
            "\n",
            "‚úì Architecture document saved to Artifacts/Documentation/architecture.md\n"
          ]
        }
      ],
      "source": [
        "architecture_prompt = f\"\"\"\n",
        "You are a senior solutions architect preparing a local-first prototype for the StaffAlloc platform. All runtime must execute on a single developer laptop without paid cloud dependencies. Align technology choices with the Day 3 FastAPI + SQLite labs (FastAPI, Pydantic, SQLAlchemy, SQLite, local file storage, optional local vector DB).\n",
        "\n",
        "## Product Context\n",
        "{prd_content}\n",
        "\n",
        "## Document Structure - Generate ALL sections below in a SINGLE, COMPLETE response:\n",
        "\n",
        "### 1. Executive Summary (2-3 paragraphs)\n",
        "- Overview of the local-first prototype approach\n",
        "- Key technology choices (FastAPI, SQLite, SQLAlchemy, local AI)\n",
        "- Goals and constraints\n",
        "\n",
        "### 2. Logical Architecture\n",
        "- **Client Layer**: React SPA, optional mobile client, CLI tools\n",
        "- **API Layer**: FastAPI routers organized by domain (users, trips, expenses, settlements, reports, ai)\n",
        "- **Service Layer**: Business logic, validation, orchestration\n",
        "- **Data Access Layer**: SQLAlchemy repositories, models\n",
        "- **Background Jobs**: APScheduler for async tasks\n",
        "- **Integration Adapters**: Local AI, vector store, file storage, SMTP\n",
        "\n",
        "### 3. Local Deployment Architecture\n",
        "- Process topology (uvicorn, React dev server, background worker)\n",
        "- Port assignments (8000 for API, 5173 for React, etc.)\n",
        "- Developer workflow (setup, run, test)\n",
        "- Directory structure\n",
        "\n",
        "### 4. Data & Storage Strategy\n",
        "- SQLite database with WAL mode\n",
        "- Alembic migrations\n",
        "- Local filesystem for receipts/reports\n",
        "- Optional Chroma/LanceDB for embeddings\n",
        "- Configuration via .env\n",
        "\n",
        "### 5. AI & Automation Features\n",
        "- Local LLM integration (Ollama/LM Studio)\n",
        "- Expense categorization pipeline\n",
        "- RAG chat implementation\n",
        "- Settlement optimization\n",
        "\n",
        "### 6. Security & Privacy\n",
        "- JWT authentication\n",
        "- Local secrets management\n",
        "- File permissions\n",
        "- Data encryption approach\n",
        "\n",
        "### 7. Testing & Quality\n",
        "- Pytest with in-memory SQLite\n",
        "- Integration test strategy\n",
        "- Linting (ruff, mypy)\n",
        "- CI/CD with GitHub Actions\n",
        "\n",
        "### 8. Observability\n",
        "- Logging (structlog)\n",
        "- Health check endpoints\n",
        "- Optional metrics/tracing\n",
        "\n",
        "### 9. Risks & Migration Path\n",
        "- Table format with risks, mitigations, and next steps\n",
        "- Evolution to cloud architecture\n",
        "\n",
        "CRITICAL: Generate the COMPLETE document with ALL sections above. Do not truncate or summarize. Provide full details for each section. The document should be 800-1200 lines of comprehensive Markdown.\n",
        "\n",
        "Respond in GitHub-flavored Markdown ready to save as `Artifacts/Documentation/architecture.md`.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Generating architecture narrative ---\")\n",
        "architecture_doc = get_completion(architecture_prompt, client, model_name, api_provider, temperature=0.3)\n",
        "print(architecture_doc[:800])\n",
        "\n",
        "save_artifact(architecture_doc, \"Artifacts/Documentation/architecture.md\")\n",
        "print(\"\\n‚úì Architecture document saved to Artifacts/Documentation/architecture.md\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 2 ‚Äì PlantUML System Diagram\n",
        "\n",
        "**Goal:** Capture the local system context as PlantUML diagrams-as-code. Request one diagram for the single-machine context and another for the FastAPI component breakdown so the visuals match the Day 3 lab stack (FastAPI, SQLite, files, local AI, MailHog). Save the PlantUML source for rendering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generating PlantUML diagrams ---\n",
            "@startuml StaffAlloc System Context\n",
            "!include <C4/C4_Context.puml>\n",
            "\n",
            "title System Context Diagram: StaffAlloc Local Development Environment\n",
            "\n",
            "LAYOUT_WITH_LEGEND()\n",
            "\n",
            "Person(pm, \"Project Manager\", \"Manages project staffing, budgets, and timelines. (e.g., Priya)\")\n",
            "Person(director, \"Director / Optimizer\", \"Oversees portfolio health and resource utilization. (e.g., David, Maria)\")\n",
            "\n",
            "System_Boundary(workstation, \"Developer Workstation\") {\n",
            "    System(web_client, \"React Web Client\", \"Vite SPA running on localhost:5173. Provides the interactive UI for managing allocations.\")\n",
            "    System(backend, \"FastAPI Bac\n",
            "\n",
            "‚úì PlantUML saved to Artifacts/Architecture/StaffAlloc_system_diagrams.puml\n"
          ]
        }
      ],
      "source": [
        "plantuml_prompt = f\"\"\"\n",
        "You are an enterprise architect creating diagrams-as-code. Using the StaffAlloc PRD and the updated local-first architecture narrative below, produce TWO COMPLETE PlantUML diagrams in a single response:\n",
        "\n",
        "## Diagram 1: System Context Diagram\n",
        "Show the complete local development environment:\n",
        "- Actors: Traveler, Trip Organizer\n",
        "- Developer Workstation boundary containing:\n",
        "  - React Web Client (localhost:5173)\n",
        "  - FastAPI Backend (localhost:8000)\n",
        "  - SQLite Database (file)\n",
        "  - Local File Storage (receipts, reports)\n",
        "  - Local Vector DB (Chroma/LanceDB)\n",
        "  - Local AI Runtime (Ollama/LM Studio)\n",
        "  - MailHog SMTP Server (localhost:8025)\n",
        "- Show all relationships and communication protocols\n",
        "\n",
        "## Diagram 2: Backend Component Diagram\n",
        "Break down the FastAPI application into:\n",
        "- API Routers (users, trips, expenses, settlements, reports, ai)\n",
        "- Service Layer (business logic)\n",
        "- Repository Layer (SQLAlchemy)\n",
        "- Domain Models (Pydantic + SQLAlchemy)\n",
        "- Background Jobs (APScheduler)\n",
        "- Adapters (AI, Vector Store, File Storage, SMTP)\n",
        "- External stores (SQLite, Filesystem, Chroma, Ollama, MailHog)\n",
        "- Show all dependencies and data flows\n",
        "\n",
        "## Product Context\n",
        "{prd_content}\n",
        "\n",
        "## Architecture Narrative\n",
        "{architecture_doc}\n",
        "\n",
        "CRITICAL REQUIREMENTS:\n",
        "- Generate BOTH complete diagrams with proper @startuml/@enduml blocks\n",
        "- Use C4-PlantUML notation (Person, System, Container, Component)\n",
        "- Include clear titles for each diagram\n",
        "- Show all relationships with descriptive labels\n",
        "- Add legends explaining colors/shapes if used\n",
        "- Output only PlantUML source code, no explanatory text\n",
        "\n",
        "Provide the complete PlantUML source for both diagrams now.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Generating PlantUML diagrams ---\")\n",
        "plantuml_source = get_completion(plantuml_prompt, client, model_name, api_provider, temperature=0.2)\n",
        "plantuml_clean = clean_llm_output(plantuml_source, language=\"plantuml\")\n",
        "print(plantuml_clean[:600])\n",
        "\n",
        "save_artifact(plantuml_clean, \"Artifacts/Architecture/StaffAlloc_system_diagrams.puml\")\n",
        "print(\"\\n‚úì PlantUML saved to Artifacts/Architecture/StaffAlloc_system_diagrams.puml\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 3 ‚Äì Architecture Decision Records (ADRs)\n",
        "\n",
        "**Goal:** Document critical architectural decisions for the local-first stack. Capture at least three ADRs that mirror the Day 3 lab choices: SQLite persistence, local AI/RAG strategy, and developer workstation runtime/tooling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generating ADRs ---\n",
            "### ADR-001: SQLite + SQLAlchemy for Local Persistence\n",
            "\n",
            "**Status:** Accepted\n",
            "**Date:** 2025-11-05\n",
            "**Context:**\n",
            "The StaffAlloc local-first prototype requires a relational database to store core entities such as projects, employees, and allocations. The primary goal is rapid development and validation on a single developer machine, prioritizing simplicity and minimizing setup overhead. The architecture narrative explicitly calls for a self-contained application without external service dependencies.\n",
            "\n",
            "The key forces at play are the need for a structured, queryable data store versus the constraint\n",
            "\n",
            "‚úì ADRs saved to Artifacts/Documentation/adrs.md\n"
          ]
        }
      ],
      "source": [
        "adr_prompt = f\"\"\"\n",
        "Act as an experienced software architect. Based on the StaffAlloc PRD and the local-first architecture narrative, author EXACTLY THREE comprehensive Architecture Decision Records (ADRs).\n",
        "\n",
        "## ADR Template - Use this structure for EACH ADR:\n",
        "\n",
        "### ADR-00X: [Clear Decision Title]\n",
        "\n",
        "**Status:** Accepted | Proposed | Deprecated\n",
        "**Date:** 2025-11-05\n",
        "**Context:** (2-3 paragraphs explaining the problem, constraints, and forces at play)\n",
        "**Decision:** (1-2 paragraphs stating what was decided and why)\n",
        "**Consequences:**\n",
        "- ‚úÖ Positive consequence 1\n",
        "- ‚úÖ Positive consequence 2\n",
        "- ‚úÖ Positive consequence 3\n",
        "- ‚ö†Ô∏è Negative consequence 1\n",
        "- ‚ö†Ô∏è Negative consequence 2\n",
        "**Alternatives Considered:** (Brief list of rejected options)\n",
        "**Follow-up Actions:** (Specific next steps or review criteria)\n",
        "\n",
        "## Required ADRs - Generate ALL THREE in full detail:\n",
        "\n",
        "### ADR-001: SQLite + SQLAlchemy for Local Persistence\n",
        "- Context: Need database for prototype, Day 3 labs use SQLite\n",
        "- Decision: Use SQLite with WAL mode, SQLAlchemy ORM, Alembic migrations\n",
        "- Consequences: Fast setup vs. limited concurrency\n",
        "- Alternatives: PostgreSQL, in-memory only\n",
        "- Follow-up: Migration path to PostgreSQL\n",
        "\n",
        "### ADR-002: Local AI/RAG with Open-Source Models\n",
        "- Context: Need AI categorization and chat without cloud costs\n",
        "- Decision: Ollama/LM Studio for LLM, Chroma for vector store\n",
        "- Consequences: Zero cost vs. lower quality/latency\n",
        "- Alternatives: OpenAI API, Google Gemini, no AI\n",
        "- Follow-up: Benchmark quality and create cloud migration plan\n",
        "\n",
        "### ADR-003: FastAPI Monolith with APScheduler\n",
        "- Context: Need async background jobs for local prototype\n",
        "- Decision: Single FastAPI process with APScheduler for jobs\n",
        "- Consequences: Simple setup vs. limited scalability\n",
        "- Alternatives: Celery+Redis, separate worker process\n",
        "- Follow-up: Define criteria for moving to distributed queue\n",
        "\n",
        "## Product Context\n",
        "{prd_content}\n",
        "\n",
        "## Architecture Narrative\n",
        "{architecture_doc}\n",
        "\n",
        "CRITICAL: Generate ALL THREE complete ADRs following the template above. Each ADR should be 15-25 lines. Total output should be 200-300 lines of comprehensive Markdown.\n",
        "\n",
        "Return complete ADRs in Markdown format suitable for `Artifacts/Documentation/adrs.md`.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Generating ADRs ---\")\n",
        "adrs_raw = get_completion(adr_prompt, client, model_name, api_provider, temperature=0.2)\n",
        "adrs_clean = clean_llm_output(adrs_raw, language=\"markdown\")\n",
        "print(adrs_clean[:600])\n",
        "\n",
        "save_artifact(adrs_clean, \"Artifacts/Documentation/adrs.md\")\n",
        "print(\"\\n‚úì ADRs saved to Artifacts/Documentation/adrs.md\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Challenge 4 ‚Äì Relational Schema Generation\n",
        "\n",
        "**Goal:** Translate the PRD and architecture outputs into a normalized relational database schema (SQLite-compatible) that we will consume in later labs. Include tables, relationships, indexes, and supporting constraints required for StaffAlloc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generating SQL schema ---\n",
            "-- StaffAlloc SQLite Schema\n",
            "-- Version: 1.0\n",
            "-- Author: Senior Data Architect\n",
            "--\n",
            "-- This schema is designed for the StaffAlloc application, optimized for a local-first\n",
            "-- prototype using SQLite. It covers core entities, relationships, and constraints\n",
            "-- derived from the PRD and architecture narrative.\n",
            "\n",
            "-- Enable foreign key constraint enforcement.\n",
            "PRAGMA foreign_keys = ON;\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "-- CORE ENTITIES\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "-- Table: users\n",
            "-- Stores information about all employees and application users.\n",
            "-- The system_role column is used for Role-Based Access Control (RBAC).\n",
            "CREATE TABLE users (\n",
            "    id INTEGER PRIMARY KEY,\n",
            "    email TEXT NOT NULL UNIQUE,\n",
            "    full_n\n",
            "\n",
            "‚úì Schema saved to artifacts/schema.sql\n"
          ]
        }
      ],
      "source": [
        "schema_prompt = f\"\"\"\n",
        "You are a senior data architect. Using the StaffAlloc PRD and architecture narrative, produce a SQLite-compatible SQL schema. Requirements:\n",
        "\n",
        "- Use `CREATE TABLE` statements with appropriate data types, primary keys, foreign keys, and `ON DELETE` behaviors.\n",
        "- Include indexes, unique constraints, and check constraints that enforce the business rules.\n",
        "- Cover core entities: users, trips, participants, expenses, expense_splits, receipts, payments, AI artefacts (e.g., RAG cache), and audit metadata.\n",
        "- Add comments (`-- ...`) explaining non-obvious design choices.\n",
        "- Optimize for analytics by including summary/materialized view candidates or helper tables if helpful.\n",
        "- End the script with any seed data or helper views only if justified by the PRD.\n",
        "\n",
        "Respond with pure SQL ready to save into `artifacts/schema.sql`.\n",
        "\n",
        "## Product Context\n",
        "{prd_content}\n",
        "\n",
        "## Architecture Narrative\n",
        "{architecture_doc}\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- Generating SQL schema ---\")\n",
        "schema_sql = get_completion(schema_prompt, client, model_name, api_provider, temperature=0.1)\n",
        "schema_clean = clean_llm_output(schema_sql, language=\"sql\")\n",
        "print(schema_clean[:800])\n",
        "\n",
        "save_artifact(schema_clean, \"artifacts/schema.sql\")\n",
        "print(\"\\n‚úì Schema saved to artifacts/schema.sql\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2 Wrap-Up\n",
        "\n",
        "You now have:\n",
        "\n",
        "- `Artifacts/Documentation/architecture.md` ‚Äì narrative architecture specification.\n",
        "- `Artifacts/Architecture/StaffAlloc_system_diagrams.puml` ‚Äì PlantUML diagrams for rendering with PlantUML/Graphviz.\n",
        "- `Artifacts/Documentation/adrs.md` ‚Äì curated architecture decision records.\n",
        "- `artifacts/schema.sql` ‚Äì normalized relational schema for StaffAlloc.\n",
        "\n",
        "These artifacts unlock Phase 3 (backend implementation). Continue the capstone by feeding the schema into the FastAPI generation workflows outlined in the Day 3 labs.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
