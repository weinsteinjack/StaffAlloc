{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77578726",
   "metadata": {},
   "source": [
    "### Configurig Models and Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the application code from Day 3 to provide context for test generation\n",
    "# TODO: potentially change this path depending on project structure\n",
    "app_code = load_artifact(\"app/main.py\")\n",
    "if not app_code:\n",
    "    print(\"Warning: Could not load app/main.py. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b2cdf",
   "metadata": {},
   "source": [
    "### Generating Tests with Fixture\n",
    "**Task:** Generate `pytest` tests for the ideal or \"happy path\" scenarios of your CRUD endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091edffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CHANGE THIS PROMPT FOR OUR FASTAPI\n",
    "# TODO: Write a prompt to generate the pytest fixture for an isolated test database.\n",
    "db_fixture_prompt = f\"\"\"\n",
    "You are a senior QA Engineer. Generate a pytest configuration file (conftest.py) for isolated database testing in a FastAPI application.\n",
    "\n",
    "FastAPI Application Code:\n",
    "{app_code}\n",
    "\n",
    "Requirements:\n",
    "1. Create a conftest.py file that contains pytest fixtures for database isolation\n",
    "2. Use an in-memory SQLite database (sqlite:///:memory:) with SQLAlchemy\n",
    "3. Import necessary modules: pytest, TestClient from fastapi.testclient, create_engine, sessionmaker, StaticPool\n",
    "4. Import from main.py: app, Base, get_db\n",
    "5. Create a database engine with StaticPool for in-memory SQLite\n",
    "6. Create a TestingSessionLocal sessionmaker bound to the test engine\n",
    "7. Create an override_get_db() function that yields a test database session and closes it\n",
    "8. Override the app's get_db dependency: app.dependency_overrides[get_db] = override_get_db\n",
    "9. Create a pytest fixture named \"client\" with scope=\"function\" that:\n",
    "   - Creates all database tables using Base.metadata.create_all(bind=engine)\n",
    "   - Yields a TestClient(app) instance\n",
    "   - Drops all tables using Base.metadata.drop_all(bind=engine) after the test\n",
    "\n",
    "Output only valid Python code for conftest.py with proper imports and fixtures. This file will be used by all test files.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Pytest DB Fixture ---\")\n",
    "if app_code:\n",
    "    generated_db_fixture = get_completion(db_fixture_prompt, client, model_name, api_provider)\n",
    "    cleaned_fixture = clean_llm_output(generated_db_fixture, language='python')\n",
    "    print(cleaned_fixture)\n",
    "    save_artifact(cleaned_fixture, \"tests/conftest.py\")\n",
    "else:\n",
    "    print(\"Skipping fixture generation because app context is missing.\")\n",
    "\n",
    "# TODO: Write a prompt to refactor the happy path tests to use the new fixture.\n",
    "refactor_tests_prompt = f\"\"\"\n",
    "You are a senior QA Engineer. Create happy path tests to use pytest fixtures from conftest.py.\n",
    "\n",
    "FastAPI Application Code:\n",
    "{app_code}\n",
    "\n",
    "Requirements:\n",
    "1. Import only pytest and TestClient (do NOT import database setup code)\n",
    "2. Import the TestClient type hint for function parameters\n",
    "3. Use the \"client\" fixture from conftest.py as a parameter in test functions\n",
    "4. Remove all database setup code (engine, sessionmaker, override_get_db, etc.) as this is now in conftest.py\n",
    "5. Keep the same test logic and assertions as the original happy path tests\n",
    "6. Ensure tests use the client fixture parameter instead of a global client\n",
    "\n",
    "Output only valid Python pytest functions that use the client fixture from conftest.py. Use descriptive function names: test_create_user and test_get_users.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Generating Refactored Tests ---\")\n",
    "if app_code:\n",
    "    refactored_tests = get_completion(refactor_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_refactored_tests = clean_llm_output(refactored_tests, language='python')\n",
    "    print(cleaned_refactored_tests)\n",
    "    save_artifact(cleaned_refactored_tests, \"tests/test_main_with_fixture.py\")\n",
    "else:\n",
    "    print(\"Skipping test refactoring because app context is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7c05c",
   "metadata": {},
   "source": [
    "### Generating Edge Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093468c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CHANGE THIS PROMPT and ADD GENERATED EDGE CASES TO TESTING FILE\n",
    "edge_case_tests_prompt = f\"\"\"\n",
    "You are a senior QA Engineer. Generate pytest test functions for edge cases and error scenarios in a FastAPI application.\n",
    "\n",
    "FastAPI Application Code:\n",
    "{app_code}\n",
    "\n",
    "Requirements:\n",
    "1. Use FastAPI's TestClient from fastapi.testclient import TestClient\n",
    "2. Import the FastAPI app instance (same setup as happy path tests)\n",
    "3. Write a test function for POST /users/ that:\n",
    "   - First creates a user with a valid email\n",
    "   - Then attempts to create another user with the same email\n",
    "   - Asserts status code is 400 (Bad Request)\n",
    "   - Verifies the error message indicates duplicate email\n",
    "4. Write a test function for GET /users/{{user_id}} that:\n",
    "   - Requests a user ID that does not exist (e.g., 99999 or a high number)\n",
    "   - Asserts status code is 404 (Not Found)\n",
    "   - Verifies an appropriate error message\n",
    "\n",
    "Output only valid Python pytest functions with proper imports. Use descriptive function names like test_create_user_duplicate_email and test_get_user_not_found. Ensure tests use the same database setup pattern as happy path tests.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Edge Case Tests ---\")\n",
    "if app_code:\n",
    "    generated_edge_case_tests = get_completion(edge_case_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_edge_case_tests = clean_llm_output(generated_edge_case_tests, language='python')\n",
    "    print(cleaned_edge_case_tests)\n",
    "else:\n",
    "    print(\"Skipping test generation because app code is missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c56c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
